{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e81b43-ccfd-4fc6-902c-59cd49aa9913",
   "metadata": {},
   "source": [
    "<p align=\"center\" width=\"100%\">\n",
    "    <img width=\"40%\" src=\"customer_support_icon.JPG\"> \n",
    "</p>\n",
    "\n",
    "A retail company is on a transformative journey, aiming to elevate their customer services through cutting-edge advancements in Speech Recognition and Natural Language Processing (NLP). As the machine learning engineer for this initiative, you are tasked with developing functionalities that not only convert customer support audio calls into text but also explore methodologies to extract insights from transcribed texts.\n",
    "\n",
    "In this dynamic project, we leverage the power of `SpeechRecognition`, `Pydub`, and `spaCy` â€“ three open-source packages that form the backbone of your solution. Your objectives are:\n",
    "  - Transcribe a sample customer audio call, stored at `sample_customer_call.wav`, to showcase the power of open-source speech recognition technology.\n",
    "  - Analyze sentiment, identify common named entities, and enhance user experience by searching for the most similar customer calls based on a given query from a subset of their pre-transcribed call data, stored at `customer_call_transcriptions.csv`.\n",
    "\n",
    "This project is an opportunity to unlock the potential of machine learning to revolutionize customer support. Let's delve into the interplay between technology and service excellence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1598e-18a8-45d5-8387-bf2f5ce4ffd6",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 25090,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1710004132772,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm",
    "outputsMetadata": {
     "0": {
      "height": 613,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pydub\n",
    "!pip install spacy\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6f3dd61-8c75-48d4-b2a5-79cd0b444ddb",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 51,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1710004132825,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries\nimport pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy",
    "outputsMetadata": {
     "0": {
      "height": 77,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "250524c2-1bd3-4ff8-a224-8fa007566c1b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1710004132873,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n",
    "outputsMetadata": {
     "0": {
      "height": 177,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Is the audio compatible for future speech recognition modeling?\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "customer_call = sr.AudioFile(\"sample_customer_call.wav\")\n",
    "\n",
    "with customer_call as source:\n",
    "    customer_audio = recognizer.record(source)\n",
    "\n",
    "transcribed_text = recognizer.recognize_google(customer_audio)\n",
    "\n",
    "customer_call = AudioSegment.from_file(\"sample_customer_call.wav\")\n",
    "\n",
    "frame_rate = customer_call.frame_rate\n",
    "number_channels = customer_call.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9da034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many calls have a true positive sentiment?\n",
    "\n",
    "df = pd.read_csv(\"customer_call_transcriptions.csv\")\n",
    "df.head()\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"sentiment_label\"]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(x):\n",
    "    compound_score = sid.polarity_scores(x)[\"compound\"]\n",
    "    if(compound_score >= 0.05):\n",
    "        return \"positive\"\n",
    "    elif(compound_score <= -0.05):\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for x in X:\n",
    "    y_pred.append(get_sentiment(x))\n",
    "\n",
    "true_positive = 0\n",
    "for i in range(len(y)):\n",
    "    if(y[i] == \"positive\" and y_pred[i] == \"positive\"):\n",
    "        true_positive += 1\n",
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8df44fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[3] == \"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee464e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yesterday'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most frequently named entity across all of the transcriptions?\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "entity_count = {}\n",
    "\n",
    "for text in df[\"text\"]:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        named_enity = ent.text\n",
    "        if named_enity not in entity_count:\n",
    "            entity_count[named_enity] = 0\n",
    "        else:\n",
    "            entity_count[named_enity] += 1\n",
    "\n",
    "max_freq = max(entity_count.values())\n",
    "most_freq_ent = [key for key in entity_count if entity_count[key] == max_freq][0]\n",
    "most_freq_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd61d95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e1931820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wrong package delivered'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which call is the most similar to \"wrong package delivery\"?\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "keyword = nlp(\"wrong package delivery\")\n",
    "similarity_score = []\n",
    "\n",
    "for text in df[\"text\"]:\n",
    "    doc = nlp(text)\n",
    "    score = doc.similarity(keyword)\n",
    "    similarity_score.append(score)\n",
    "\n",
    "max_index = similarity_score.index(max(similarity_score))\n",
    "most_similar_text = df[\"text\"][max_index]\n",
    "most_similar_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd8316f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n",
      "1\n",
      "2\n",
      "yesterday\n",
      "wrong package delivered\n"
     ]
    }
   ],
   "source": [
    "print(frame_rate)\n",
    "print(number_channels)\n",
    "print(true_positive)\n",
    "print(most_freq_ent)\n",
    "print(most_similar_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
